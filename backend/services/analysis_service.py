import os
import json
import io
import re
import asyncio
from loguru import logger

from backend.api.models import PreparationAnalysis, ResultsAnalysis, ScoreBreakdown
from ..core.config import settings

from backend.agents.pipeline_1_pre_interview.agent_1_data_parser import agent_1_data_parser
from backend.agents.pipeline_1_pre_interview.agent_2_profiler import agent_2_profiler
from backend.agents.pipeline_1_pre_interview.agent_3_plan_generator import agent_3_plan_generator
from backend.agents.pipeline_2_post_interview.agent_4_data_extractor import agent_4_data_extractor

import assemblyai as aai
from pypdf import PdfReader
import docx
from google.adk.runners import Runner
from google.adk.sessions import InMemorySessionService
from google.genai import types
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload


class AnalysisService:
    """Service responsible for interview analysis business logic using AI Agents"""

    def __init__(self):
        aai.settings.api_key = settings.assemblyai_api_key
        if not aai.settings.api_key:
            logger.warning("API –∫–ª—é—á –¥–ª—è AssemblyAI –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –≤ .env —Ñ–∞–π–ª–µ!")
        else:
            logger.success("–ö–ª–∏–µ–Ω—Ç AssemblyAI —Å–∫–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä–æ–≤–∞–Ω.")

        self.drive_service = None
        try:
            credentials_path = settings.google_application_credentials

            credentials = service_account.Credentials.from_service_account_file(
                credentials_path
            )
            self.drive_service = build('drive', 'v3', credentials=credentials)
            logger.success("–ö–ª–∏–µ–Ω—Ç Google Drive API —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–ª–∏–µ–Ω—Ç–∞ Google Drive API: {e}")

    def _get_google_drive_file_id(self, link: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç ID —Ñ–∞–π–ª–∞ –∏–∑ —Å—Å—ã–ª–∫–∏ –Ω–∞ Google Drive."""
        match = re.search(r'/file/d/([a-zA-Z0-9_-]+)', link)
        if match:
            return match.group(1)
        raise ValueError("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ Google Drive. –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å ID —Ñ–∞–π–ª–∞.")

    async def _download_audio_from_drive(self, file_id: str) -> io.BytesIO:
        """
        –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –∑–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∞–π–ª –∏–∑ Google Drive, –∏—Å–ø–æ–ª—å–∑—É—è —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –±–∏–±–ª–∏–æ—Ç–µ–∫—É.
        """
        if not self.drive_service:
            raise ConnectionError("–°–µ—Ä–≤–∏—Å Google Drive –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —É—á–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.")

        logger.info(f"–ù–∞—á–∞–ª–æ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ —Å ID: {file_id} –∏–∑ Google Drive.")

        try:
            request = self.drive_service.files().get_media(fileId=file_id)
            file_io = io.BytesIO()
            downloader = MediaIoBaseDownload(file_io, request)

            def download_in_thread():
                done = False
                while not done:
                    status, done = downloader.next_chunk()
                    if status:
                        logger.info(f"–ü—Ä–æ–≥—Ä–µ—Å—Å –∑–∞–≥—Ä—É–∑–∫–∏: {int(status.progress() * 100)}%.")

            await asyncio.to_thread(download_in_thread)

            logger.success(f"–§–∞–π–ª {file_id} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω.")
            file_io.seek(0)
            return file_io

        except Exception as e:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª –∏–∑ Google Drive: {e}")
            raise IOError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞ —Å Google Drive. "
                          f"–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—ã –ø–æ–¥–µ–ª–∏–ª–∏—Å—å —Ñ–∞–π–ª–æ–º —Å email –≤–∞—à–µ–≥–æ —Å–µ—Ä–≤–∏—Å–Ω–æ–≥–æ –∞–∫–∫–∞—É–Ω—Ç–∞.")

    async def _transcribe_audio_assemblyai(self, audio_data: io.BytesIO) -> str:
        """
        –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ —Å –ø–æ–º–æ—â—å—é AssemblyAI SDK, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è—è —è–∑—ã–∫.
        """
        logger.info("–ù–∞—á–∞–ª–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ AssemblyAI —Å –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —è–∑—ã–∫–∞...")

        config = aai.TranscriptionConfig(language_detection=True)
        transcriber = aai.Transcriber(config=config)
        transcript = await transcriber.transcribe_async(audio_data)

        if transcript.status == aai.TranscriptStatus.error:
            logger.error(f"–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ AssemblyAI: {transcript.error}")
            raise ValueError(f"Transcription failed: {transcript.error}")

        detected_language = transcript.language_code
        confidence = transcript.language_confidence or 0
        logger.success(f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è AssemblyAI —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. "
                       f"–û–ø—Ä–µ–¥–µ–ª–µ–Ω —è–∑—ã–∫: {detected_language} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f})")

        if confidence < 0.7:
            logger.warning(f"–ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ —è–∑—ã–∫–∞ ({confidence:.2f}). "
                           f"–†–µ–∑—É–ª—å—Ç–∞—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Ç–æ—á–Ω—ã–º.")

        return transcript.text or ""

    # PIPELINE 1

    async def analyze_preparation(self, profile: str, cv_file: io.BytesIO, filename: str) -> PreparationAnalysis:
        logger.info("–ù–∞—á–∞–ª–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∫ –∏–Ω—Ç–µ—Ä–≤—å—é...")

        api_key_to_use = settings.google_api_key
        if not api_key_to_use:
            logger.error("Google API key –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω.")
            raise ValueError("Google API key is not provided.")

        # ---–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º API –∫–ª—é—á –∫–∞–∫ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è ---
        os.environ['GOOGLE_API_KEY'] = api_key_to_use
        logger.success("API –∫–ª—é—á Google —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∫–∞–∫ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è.")

        logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞: {filename}")
        cv_text = ""
        try:
            if filename.lower().endswith('.pdf'):
                reader = PdfReader(cv_file)
                cv_text = "\n".join(page.extract_text() or "" for page in reader.pages)
                logger.success("–¢–µ–∫—Å—Ç –∏–∑ PDF —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω.")
            elif filename.lower().endswith('.docx'):
                doc = docx.Document(cv_file)
                full_text = []
                for para in doc.paragraphs:
                    if para.text.strip():
                        full_text.append(para.text)
                full_text.append("\n--- –¢–∞–±–ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ ---\n")
                for table in doc.tables:
                    for row in table.rows:
                        row_text = " | ".join(cell.text for cell in row.cells)
                        if row_text.strip():
                            full_text.append(row_text)
                    full_text.append("\n")
                cv_text = "\n".join(full_text)
                logger.success("–¢–µ–∫—Å—Ç –∏–∑ DOCX —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω.")
            else:
                cv_text = cv_file.read().decode('utf-8', errors='ignore')
                logger.success("–§–∞–π–ª –ø—Ä–æ—á–∏—Ç–∞–Ω –∫–∞–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã–π.")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {filename}: {e}")
            raise ValueError(f"Could not process file: {filename}")

        logger.debug(f"–ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Ä–µ–∑—é–º–µ (–ø–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤): {cv_text[:200]}...")

        # TODO: –ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ ID –¥–ª—è –º–Ω–æ–≥–æ–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ —Ä–µ–∂–∏–º–∞
        session_service = InMemorySessionService()
        session_id = "preparation_session_123"
        user_id = "prep_user"
        await session_service.create_session(app_name=settings.app_name, user_id=user_id, session_id=session_id)

        logger.info("üöÄ –ó–∞–ø—É—Å–∫ agent_1_data_parser...")
        runner_1 = Runner(agent=agent_1_data_parser, app_name=settings.app_name, session_service=session_service)
        message_for_agent_1 = types.Content(role="user", parts=[types.Part(text=cv_text), types.Part(
            text=f"### –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –≤–∞–∫–∞–Ω—Å–∏–∏\n{profile}")])
        agent_1_output = ""
        async for event in runner_1.run_async(session_id=session_id, user_id=user_id,
                                              new_message=message_for_agent_1):  # –ö–ª—é—á –±–æ–ª—å—à–µ –Ω–µ –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –∑–¥–µ—Å—å
            if event.content and event.content.parts:
                agent_1_output += "".join(part.text for part in event.content.parts if part.text)

        logger.success("‚úÖ agent_1_data_parser –∑–∞–≤–µ—Ä—à–∏–ª —Ä–∞–±–æ—Ç—É.")
        logger.debug(f"–í—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ê–≥–µ–Ω—Ç–∞ 1 (JSON):\n{agent_1_output}")

        logger.info("üöÄ –ó–∞–ø—É—Å–∫ agent_2_profiler...")
        runner_2 = Runner(agent=agent_2_profiler, app_name=settings.app_name, session_service=session_service)
        message_for_agent_2 = types.Content(role="user", parts=[types.Part(text=agent_1_output)])
        agent_2_output = ""
        async for event in runner_2.run_async(session_id=session_id, user_id=user_id, new_message=message_for_agent_2):
            if event.content and event.content.parts:
                agent_2_output += "".join(part.text for part in event.content.parts if part.text)

        logger.success("‚úÖ agent_2_profiler –∑–∞–≤–µ—Ä—à–∏–ª —Ä–∞–±–æ—Ç—É.")
        logger.debug(f"–í—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ê–≥–µ–Ω—Ç–∞ 2 (–¢–µ–∫—Å—Ç–æ–≤—ã–π –ø—Ä–æ—Ñ–∏–ª—å):\n{agent_2_output}")

        logger.info("üöÄ –ó–∞–ø—É—Å–∫ agent_3_plan_generator...")
        runner_3 = Runner(agent=agent_3_plan_generator, app_name=settings.app_name, session_service=session_service)
        message_for_agent_3 = types.Content(role="user", parts=[types.Part(text=agent_2_output)])
        final_output = ""
        async for event in runner_3.run_async(session_id=session_id, user_id=user_id, new_message=message_for_agent_3):
            if event.content and event.content.parts:
                final_output += "".join(part.text for part in event.content.parts if part.text)

        logger.success("‚úÖ agent_3_plan_generator –∑–∞–≤–µ—Ä—à–∏–ª —Ä–∞–±–æ—Ç—É.")
        logger.debug(f"–§–∏–Ω–∞–ª—å–Ω—ã–µ –≤—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç –ê–≥–µ–Ω—Ç–∞ 3:\n{final_output}")

        logger.info("–ü–∞—Ä—Å–∏–Ω–≥ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞ –≤ –æ–±—ä–µ–∫—Ç Pydantic...")
        try:
            clean_json_str = final_output.strip().replace("```json", "").replace("```", "").strip()
            data = json.loads(clean_json_str)

            data["message"] = "Interview preparation plan created successfully."

            result = PreparationAnalysis(**data)
            logger.success("–ü—Ä–æ—Ü–µ—Å—Å –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∫ –∏–Ω—Ç–µ—Ä–≤—å—é —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω.")
            return result
        except json.JSONDecodeError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è JSON –æ—Ç –ê–≥–µ–Ω—Ç–∞ 3: {e}")
            logger.error(f"–ü–æ–ª—É—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: {final_output}")
            raise ValueError("AI-—Å–µ—Ä–≤–∏—Å –≤–µ—Ä–Ω—É–ª –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö.")

    # PIPELINE 2

    async def analyze_results(self, video_link: str, matrix_content: bytes) -> ResultsAnalysis:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–Ω—Ç–µ—Ä–≤—å—é, –∑–∞–ø—É—Å–∫–∞—è –ø–∞–π–ø–ª–∞–π–Ω 2.
        """
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ –ü–∞–π–ø–ª–∞–π–Ω–∞ 2: –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–Ω—Ç–µ—Ä–≤—å—é...")
        try:
            file_id = self._get_google_drive_file_id(video_link)
            audio_file_stream = await self._download_audio_from_drive(file_id)
            transcription_text = await self._transcribe_audio_assemblyai(audio_file_stream)

            logger.info(f"–ü–æ–ª—É—á–µ–Ω–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è (–ø–µ—Ä–≤—ã–µ 100 —Å–∏–º–≤–æ–ª–æ–≤): {transcription_text[:100]}...")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –Ω–∞ —ç—Ç–∞–ø–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö (–ê–≥–µ–Ω—Ç 4): {e}")
            raise ValueError(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ –∏–ª–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {e}")

        # --- –ü–æ—Å–ª–µ–¥—É—é—â–∏–µ –∞–≥–µ–Ω—Ç—ã (–ø–æ–∫–∞ –∑–∞–≥–ª—É—à–∫–∏) ---
        # –ó–¥–µ—Å—å –±—É–¥—É—Ç –≤—ã–∑–æ–≤—ã –ê–≥–µ–Ω—Ç–æ–≤ 5, 6, 7

        logger.success("‚úÖ –ü–∞–π–ø–ª–∞–π–Ω 2 —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–∏–ª —Ä–∞–±–æ—Ç—É (—Å –∑–∞–≥–ª—É—à–∫–∞–º–∏).")

        # –ú–æ–∫–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
        return ResultsAnalysis(
            message="Interview analysis completed successfully",
            transcription=transcription_text,
            scores=ScoreBreakdown(
                technical=90, communication=85, leadership=88, cultural=80, overall=85
            ),
            strengths=["–û—Ç–ª–∏—á–Ω—ã–µ –∑–Ω–∞–Ω–∏—è –≤ –æ–±–ª–∞—Å—Ç–∏ –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–∏—Å—Ç–µ–º.", "–°–∏–ª—å–Ω—ã–µ –∫–æ–º–º—É–Ω–∏–∫–∞—Ç–∏–≤–Ω—ã–µ –Ω–∞–≤—ã–∫–∏."],
            concerns=["–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≥–ª—É–±–æ–∫–∏–π –æ–ø—ã—Ç –≤ –¥–æ–∫–µ—Ä–µ.", "–¢—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."],
            recommendation="RECOMMEND HIRE",
            reasoning="–ö–∞–Ω–¥–∏–¥–∞—Ç –ø–æ–∫–∞–∑–∞–ª —Å–µ–±—è –∫–∞–∫ —Å–∏–ª—å–Ω—ã–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç —Å —Ö–æ—Ä–æ—à–∏–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–æ–º —Ä–æ—Å—Ç–∞.",
            topicsDiscussed=["–ú–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å—ã", "–ë–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö", "–û–ø—ã—Ç –≤ –∫–æ–º–∞–Ω–¥–µ"]
        )
