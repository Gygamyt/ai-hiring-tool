import os
import json
import io
import re
import asyncio
from typing import Tuple
from loguru import logger

from backend.api.models import PreparationAnalysis, ResultsAnalysis, ScoreBreakdown
from ..core.config import settings

from backend.agents.pipeline_1_pre_interview.agent_1_data_parser import agent_1_data_parser
from backend.agents.pipeline_1_pre_interview.agent_2_grader import agent_2_grader
from backend.agents.pipeline_1_pre_interview.agent_3_report_generator import agent_3_report_generator
from backend.agents.pipeline_2_post_interview.agent_4_topic_extractor import agent_4_topic_extractor
from backend.agents.pipeline_2_post_interview.agent_5_final_report_generator import agent_5_final_report_generator

import assemblyai as aai
from pypdf import PdfReader
import docx
from google.adk.runners import Runner
from google.adk.sessions import InMemorySessionService
from google.genai import types
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload
from docx import Document
from docx.shared import Pt


class AnalysisService:
    """Service responsible for interview analysis business logic using AI Agents"""

    def __init__(self):
        if settings.assemblyai_api_key:
            aai.settings.api_key = settings.assemblyai_api_key
            logger.success("–ö–ª–∏–µ–Ω—Ç AssemblyAI —Å–∫–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä–æ–≤–∞–Ω.")
        else:
            logger.warning("API –∫–ª—é—á –¥–ª—è AssemblyAI –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –≤ .env —Ñ–∞–π–ª–µ!")

        self.drive_service = None
        try:
            credentials_path = settings.google_application_credentials
            if os.path.exists(credentials_path):
                credentials = service_account.Credentials.from_service_account_file(credentials_path)
                self.drive_service = build('drive', 'v3', credentials=credentials)
                logger.success("–ö–ª–∏–µ–Ω—Ç Google Drive API —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
            else:
                logger.error(f"–§–∞–π–ª —É—á–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö Google –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ –ø—É—Ç–∏: {credentials_path}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–ª–∏–µ–Ω—Ç–∞ Google Drive API: {e}")

    def _set_google_api_key(self):
        """
        –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∫–ª—é—á Google API –∫–∞–∫ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è.
        """
        api_key_to_use = settings.google_api_key
        if not api_key_to_use:
            logger.error("–ö–ª—é—á Google API (google_api_key) –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ.")
            raise ValueError("Google API key is not provided.")
        os.environ['GOOGLE_API_KEY'] = api_key_to_use
        logger.info("–ö–ª—é—á Google API —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∫–∞–∫ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.")

    def _get_google_drive_file_id(self, link: str) -> str:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç ID —Ñ–∞–π–ª–∞ –∏–∑ —Å—Å—ã–ª–∫–∏ –Ω–∞ Google Drive.
        """
        patterns = [
            r'/file/d/([a-zA-Z0-9_-]+)',
            r'/spreadsheets/d/([a-zA-Z0-9_-]+)'
        ]
        for pattern in patterns:
            match = re.search(pattern, link)
            if match:
                return match.group(1)
        raise ValueError("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ Google Drive. –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å ID —Ñ–∞–π–ª–∞.")

    async def _download_sheet_from_drive(self, file_id: str) -> str:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç Google –¢–∞–±–ª–∏—Ü—É –∫–∞–∫ CSV –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ.
        """
        if not self.drive_service:
            raise ConnectionError("–°–µ—Ä–≤–∏—Å Google Drive –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
        logger.info(f"–ù–∞—á–∞–ª–æ –∑–∞–≥—Ä—É–∑–∫–∏ —Ç–∞–±–ª–∏—Ü—ã —Å ID: {file_id} –∏–∑ Google Drive.")
        try:
            request = self.drive_service.files().export_media(fileId=file_id, mimeType='text/csv')
            file_io = io.BytesIO()
            downloader = MediaIoBaseDownload(file_io, request)

            def download_in_thread():
                done = False
                while not done:
                    _, done = downloader.next_chunk()

            await asyncio.to_thread(download_in_thread)
            logger.success(f"–¢–∞–±–ª–∏—Ü–∞ {file_id} —É—Å–ø–µ—à–Ω–æ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ –≤ CSV.")
            file_io.seek(0)
            return file_io.read().decode('utf-8')
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ —Ç–∞–±–ª–∏—Ü—ã –∏–∑ Google Drive: {e}", exc_info=True)
            raise IOError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∏–∑ Google Drive: {e}")

    async def _download_audio_from_drive(self, file_id: str) -> io.BytesIO:
        """
        –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –∞—É–¥–∏–æ/–≤–∏–¥–µ–æ —Ñ–∞–π–ª –∏–∑ Google Drive.
        """
        if not self.drive_service:
            raise ConnectionError("–°–µ—Ä–≤–∏—Å Google Drive –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —É—á–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.")
        logger.info(f"–ù–∞—á–∞–ª–æ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ —Å ID: {file_id} –∏–∑ Google Drive.")
        try:
            request = self.drive_service.files().get_media(fileId=file_id)
            file_io = io.BytesIO()
            downloader = MediaIoBaseDownload(file_io, request)

            def download_in_thread():
                done = False
                while not done:
                    status, done = downloader.next_chunk()
                    if status:
                        logger.info(f"–ü—Ä–æ–≥—Ä–µ—Å—Å –∑–∞–≥—Ä—É–∑–∫–∏: {int(status.progress() * 100)}%.")

            await asyncio.to_thread(download_in_thread)
            logger.success(f"–§–∞–π–ª {file_id} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω.")
            file_io.seek(0)
            return file_io
        except Exception as e:
            logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ —Å–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª –∏–∑ Google Drive: {e}", exc_info=True)
            raise e

    def _read_file_content(self, file: io.BytesIO, filename: str) -> str:
        """
        –ß–∏—Ç–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ (PDF, DOCX, TXT) –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç.
        """
        logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞: {filename}")
        try:
            if filename.lower().endswith('.pdf'):
                reader = PdfReader(file)
                return "\n".join(page.extract_text() or "" for page in reader.pages)
            elif filename.lower().endswith('.docx'):
                doc = docx.Document(file)
                full_text = [para.text for para in doc.paragraphs if para.text.strip()]
                return "\n".join(full_text)
            else:
                return file.read().decode('utf-8', errors='ignore')
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {filename}: {e}")
            raise ValueError(f"Could not process file: {filename}")

    async def analyze_preparation(
            self,
            cv_file: io.BytesIO,
            cv_filename: str,
            feedback_text: str,
            requirements_link: str
    ) -> PreparationAnalysis:
        logger.info("–ù–∞—á–∞–ª–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ—Ü–µ–Ω–∫–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ (–ü–∞–π–ø–ª–∞–π–Ω 1)...")

        self._set_google_api_key()

        cv_text = self._read_file_content(cv_file, cv_filename)

        requirements_file_id = self._get_google_drive_file_id(requirements_link)
        requirements_text = await self._download_sheet_from_drive(requirements_file_id)

        session_service = InMemorySessionService()
        session_id = f"prep_session_{os.urandom(8).hex()}"
        user_id = "prep_user"
        await session_service.create_session(app_name=settings.app_name, user_id=user_id, session_id=session_id)

        logger.info("üöÄ –ó–∞–ø—É—Å–∫ agent_1_data_parser...")
        runner_1 = Runner(agent=agent_1_data_parser, app_name=settings.app_name, session_service=session_service)
        message_for_agent_1 = types.Content(
            role="user",
            parts=[
                types.Part(text=f"cv_text: {cv_text}"),
                types.Part(text=f"requirements_text: {requirements_text}"),
                types.Part(text=f"feedback_text: {feedback_text}")
            ]
        )
        agent_1_output = ""
        async for event in runner_1.run_async(session_id=session_id, user_id=user_id, new_message=message_for_agent_1):
            if event.content and event.content.parts:
                agent_1_output += "".join(part.text for part in event.content.parts if part.text)

        logger.info("üöÄ –ó–∞–ø—É—Å–∫ agent_2_grader...")
        runner_2 = Runner(agent=agent_2_grader, app_name=settings.app_name, session_service=session_service)
        message_for_agent_2 = types.Content(role="user", parts=[types.Part(text=agent_1_output)])
        agent_2_output = ""
        async for event in runner_2.run_async(session_id=session_id, user_id=user_id, new_message=message_for_agent_2):
            if event.content and event.content.parts:
                agent_2_output += "".join(part.text for part in event.content.parts if part.text)

        logger.info("üöÄ –ó–∞–ø—É—Å–∫ agent_3_report_generator...")
        runner_3 = Runner(agent=agent_3_report_generator, app_name=settings.app_name, session_service=session_service)
        message_for_agent_3 = types.Content(role="user", parts=[types.Part(text=agent_2_output)])
        final_output = ""
        async for event in runner_3.run_async(session_id=session_id, user_id=user_id, new_message=message_for_agent_3):
            if event.content and event.content.parts:
                final_output += "".join(part.text for part in event.content.parts if part.text)

        logger.info("–ü–∞—Ä—Å–∏–Ω–≥ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞...")
        try:
            clean_json_str = final_output.strip().replace("```json", "").replace("```", "").strip()
            data = json.loads(clean_json_str)

            final_response_data = {
                "message": "Interview preparation report created successfully.",
                **data
            }
            return PreparationAnalysis(**final_response_data)
        except json.JSONDecodeError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è JSON –æ—Ç –ê–≥–µ–Ω—Ç–∞ 3: {e}\n–ü–æ–ª—É—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: {final_output}")
            raise ValueError("AI-—Å–µ—Ä–≤–∏—Å –≤–µ—Ä–Ω—É–ª –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö.")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ Pydantic –∏–ª–∏ –¥—Ä—É–≥–∞—è –æ—à–∏–±–∫–∞: {e}")
            raise ValueError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞: {e}")

    async def _transcribe_audio_assemblyai(self, audio_data: io.BytesIO) -> str:
        logger.info("–ù–∞—á–∞–ª–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ AssemblyAI —Å –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —è–∑—ã–∫–∞...")

        config = aai.TranscriptionConfig(language_detection=True)
        transcriber = aai.Transcriber(config=config)

        def sync_transcribe_task():
            logger.info("–ó–∞–ø—É—Å–∫ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –∑–∞–¥–∞—á–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ...")
            return transcriber.transcribe(audio_data)

        transcript = await asyncio.to_thread(sync_transcribe_task)

        if transcript.status == aai.TranscriptStatus.error:
            logger.error(f"–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ AssemblyAI: {transcript.error}")
            raise ValueError(f"Transcription failed: {transcript.error}")

        logger.success("–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è AssemblyAI —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")

        if not transcript.text:
            logger.warning("–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –≤–µ—Ä–Ω—É–ª–∞ –ø—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç.")

        return transcript.text or ""

    async def analyze_results(self, video_link: str, matrix_content: bytes) -> ResultsAnalysis:
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ –ü–∞–π–ø–ª–∞–π–Ω–∞ 2: –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–Ω—Ç–µ—Ä–≤—å—é...")

        self._set_google_api_key()

        file_id = self._get_google_drive_file_id(video_link)
        audio_file_stream = await self._download_audio_from_drive(file_id)
        transcription_text = await self._transcribe_audio_assemblyai(audio_file_stream)
        if not transcription_text:
            raise ValueError("–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –Ω–µ –≤–µ—Ä–Ω—É–ª–∞ —Ç–µ–∫—Å—Ç.")

        session_service = InMemorySessionService()
        session_id = f"results_session_{os.urandom(8).hex()}"
        user_id = "results_user"
        await session_service.create_session(app_name=settings.app_name, user_id=user_id, session_id=session_id)

        logger.info("üöÄ –ó–∞–ø—É—Å–∫ agent_4_topic_extractor...")
        runner_4 = Runner(agent=agent_4_topic_extractor, app_name=settings.app_name, session_service=session_service)
        message_for_agent_5 = types.Content(role="user", parts=[types.Part(text=transcription_text)])
        agent_5_output = ""
        async for event in runner_4.run_async(session_id=session_id, user_id=user_id, new_message=message_for_agent_5):
            if event.content and event.content.parts:
                agent_5_output += "".join(part.text for part in event.content.parts if part.text)

        logger.info("üöÄ –ó–∞–ø—É—Å–∫ agent_5_final_report_generator...")
        runner_5 = Runner(agent=agent_5_final_report_generator, app_name=settings.app_name,
                          session_service=session_service)
        combined_input_for_agent_6 = f"### –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∏–Ω—Ç–µ—Ä–≤—å—é:\n{transcription_text}\n\n### –ú–∞—Ç—Ä–∏—Ü–∞ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π:\n{matrix_content.decode('utf-8', errors='ignore')}"
        message_for_agent_6 = types.Content(role="user", parts=[types.Part(text=combined_input_for_agent_6)])
        agent_6_output = ""
        async for event in runner_5.run_async(session_id=session_id, user_id=user_id, new_message=message_for_agent_6):
            if event.content and event.content.parts:
                agent_6_output += "".join(part.text for part in event.content.parts if part.text)

        logger.info("–ü–∞—Ä—Å–∏–Ω–≥ –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
        try:
            clean_json_str_5 = agent_5_output.strip().replace("```json", "").replace("```", "").strip()
            topics_data = json.loads(clean_json_str_5)

            clean_json_str_6 = agent_6_output.strip().replace("```json", "").replace("```", "").strip()
            report_data = json.loads(clean_json_str_6)

            return ResultsAnalysis(
                message="Interview analysis completed successfully",
                transcription=transcription_text,
                scores=ScoreBreakdown(**report_data.get("scores", {})),
                strengths=report_data.get("strengths", []),
                concerns=report_data.get("concerns", []),
                recommendation=report_data.get("recommendation", "N/A"),
                reasoning=report_data.get("reasoning", ""),
                topicsDiscussed=topics_data.get("topicsDiscussed", [])
            )
        except json.JSONDecodeError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è JSON: {e}")
            logger.error(f"–ü—Ä–æ–±–ª–µ–º–Ω—ã–π JSON –æ—Ç –ê–≥–µ–Ω—Ç–∞ 5: {agent_5_output}")
            logger.error(f"–ü—Ä–æ–±–ª–µ–º–Ω—ã–π JSON –æ—Ç –ê–≥–µ–Ω—Ç–∞ 6: {agent_6_output}")
            raise ValueError("AI-—Å–µ—Ä–≤–∏—Å –≤–µ—Ä–Ω—É–ª –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö.")

    def create_docx_report(self, results: ResultsAnalysis) -> io.BytesIO:
        """–°–æ–∑–¥–∞–µ—Ç –æ—Ç—á–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ DOCX –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞."""

        document = Document()

        heading = document.add_heading('–û—Ç—á–µ—Ç –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –∏–Ω—Ç–µ—Ä–≤—å—é', level=1)
        run = heading.runs[0]
        run.font.name = 'Calibri'
        run.font.size = Pt(18)

        document.add_heading('–§–∏–Ω–∞–ª—å–Ω–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è', level=2)
        p = document.add_paragraph()

        run_verdict_label = p.add_run("–í–µ—Ä–¥–∏–∫—Ç: ")
        run_verdict_label.bold = True
        run_verdict_label.font.name = 'Calibri'
        run_verdict_label.font.size = Pt(12)

        run_verdict_text = p.add_run(results.recommendation)
        run_verdict_text.font.name = 'Calibri'
        run_verdict_text.font.size = Pt(12)

        p_reasoning = document.add_paragraph(results.reasoning)
        for run in p_reasoning.runs:
            run.font.name = 'Calibri'
            run.font.size = Pt(12)

        document.add_heading('–û—Ü–µ–Ω–∫–∞ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π', level=2)
        table = document.add_table(rows=1, cols=2)
        table.style = 'Table Grid'
        hdr_cells = table.rows[0].cells
        hdr_cells[0].text = '–ö–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—è'
        hdr_cells[1].text = '–û—Ü–µ–Ω–∫–∞ (%)'

        for key, value in results.scores.model_dump().items():
            row_cells = table.add_row().cells
            row_cells[0].text = key.capitalize()
            row_cells[1].text = str(value)

        for row in table.rows:
            for cell in row.cells:
                for paragraph in cell.paragraphs:
                    for run in paragraph.runs:
                        run.font.name = 'Calibri'
                        run.font.size = Pt(10)

        document.add_heading('–ö–ª—é—á–µ–≤—ã–µ —Å–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã', level=2)
        for strength in results.strengths:
            p_strength = document.add_paragraph(strength, style='List Bullet')
            for run in p_strength.runs:
                run.font.name = 'Calibri'
                run.font.size = Pt(12)

        document.add_heading('–û–±–ª–∞—Å—Ç–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è', level=2)
        for concern in results.concerns:
            p_concern = document.add_paragraph(concern, style='List Bullet')
            for run in p_concern.runs:
                run.font.name = 'Calibri'
                run.font.size = Pt(12)

        file_stream = io.BytesIO()
        document.save(file_stream)
        file_stream.seek(0)

        return file_stream
